# -*- coding: utf-8 -*-
"""ML Assignment1_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1twnup-CdFsaJl297EheMzjPN59hS0sNV
"""
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from mpl_toolkits import mplot3d
# print(sys.argv)

url = sys.argv[1]+'/X.csv'
# url = 'https://raw.githubusercontent.com/RealGagandeep/DataSet-for-ML/main/data/q1/linearX.csv'
dx = pd.read_csv(url)

url = sys.argv[2]+'/Y.csv'
# url = 'https://raw.githubusercontent.com/RealGagandeep/DataSet-for-ML/main/data/q1/linearY.csv'
dy = pd.read_csv(url)

arr1 = pd.DataFrame(dx)
x = arr1.to_numpy()

arr2 = pd.DataFrame(dy)
y = arr2.to_numpy()

theta0 = 5                   # Initial value of 0_not
theta1 = 5                   # Initial value of 0_one
eta = 0.1                     # Learning rate
errorVal = 6.4*10**-6         # Stopping creiteria
count = 0                     # Counter of iterations

def stdev(l):                 # Function to calculate std. dev.
  psum = 0
  lmean = np.mean(l)
  for i in range(len(l)):
    psum = psum + (lmean-float(l[i]))**2
  return np.sqrt(psum/len(l))

def error(newY,newX,yActual): # Function to calculate error Returns MSE value
  error=[]
  for i in range(len(newX)):
    val = ((newY[i])-yActual)**2
    error.append((val))
  return np.mean(error)

newX = (x-np.mean(x))/stdev(x)          # Normalizing the x - data and changing variable name
newY = y                                # Changing variable name
j0=[]                                   # List of error value at every iteration
yActual = []                            # Making an array for hypothesis function
err = 1                                 # Innitializing the error value to enter the loop

theta0Store = []                                    # List of new values of 0_not to plot the graph                  
theta1Store = []                                    # List of new values of 0_one to plot the graph
                 
while(err>errorVal):                                # Loop till the stopping crieteria is met
  yActual=[]                                        # Initializing the yActual again to make updation in hypothesis function
  count+=1                                          # Incrementing the iteration counter

  for i in range(len(newY)):
    yActual.append(theta0 + theta1*newX[i])         # Defining the hypothesis function
    
  err = error(newY,newX,yActual)
  j0.append(err)

  del0 = -(newY - yActual)                          # Calculating the gradient of 0_not
  del1 = -newX*(newY - yActual)                     # Calculating the gradient of 0_one

  theta0Store.append(theta0)
  theta1Store.append(theta1)

  theta0 = theta0 - eta*np.mean(del0)               # Updating the 0_not
  theta1 = theta1 - eta*np.mean(del1)               # Updating the 0_one


# plt.scatter(newX, newY, color = "red", marker = ".", s = 20)

# y_pred = theta0 +theta1*newX              # Defining the predicted hypothesis function after training

# plt.plot(newX, y_pred, color = "black")   # Plotting the predicted hypothesis function

# plt.xlabel('x')                           # Labelling X
# plt.ylabel('y')                           # Labelling Y

# plt.show()                                # Showing the final plot

# figure,axis_1 = plt.subplots()

# color = 'tab:red'
# axis_2 = axis_1.twinx()
# axis_2.plot(j0, label='ERROR', color=color)
# axis_2.set_title('Values of theta and J_theta with number of iterations')

# figure.legend();

def f(a,b,newX,newY):                                 # Defining a function to take
  output = []                                         # all possible pairs of theta0 and theta1
  for i in range(len(a)):                             # to make surface plot
    for j in range(len(b)):
      output.append(errfn(a[i],b[j],newX,newY))
  return output

def errfn(a,b,newX,newY):                             # Defining a function to calculate
  z = []                                              # the error values at correseponding 
  for  m in range(len(newX)):                         # values of theta0 and theata1
    val = (a + b*newX[m] - newY[m])**2
    z.append(val)
  k = np.mean(z)
  return k

# a = np.linspace(-9.9,9.9,len(newX))                  # Making a uniformly spaced theta0 array
# b = np.linspace(-9.9,9.9,len(newX))                  # MAking a uniformly spaced theta1 array
# X, Y = np.meshgrid(a, b)

# z= f(a,b,newX,newY)
# Z = np.array(z).reshape(len(newX),len(newY))

# fig = plt.figure()
# ax = plt.axes(projection='3d')

# ax.plot_surface(X, Y, Z,cmap='cool', edgecolor='none')
# ax.set_title('Surface plot')
# ax.plot(theta0Store, theta1Store, j0, color='black', marker= '*')

# plt.show()

# plt.contour(X, Y, Z)
# plt.plot(theta0Store, theta1Store,color='black', marker= '.')

# plt.show()


url = sys.argv[3]+'/X.csv'
# url = 'https://raw.githubusercontent.com/RealGagandeep/DataSet-for-ML/main/data/q1/X.csv'
dx = pd.read_csv(url)

arr1 = pd.DataFrame(dx)
xTest = arr1.to_numpy()

# url = 'https://raw.githubusercontent.com/RealGagandeep/DataSet-for-ML/main/data/q1/true_Y.csv'
# dy = pd.read_csv(url)

# arr1 = pd.DataFrame(dy)
# yTest = arr1.to_numpy()

yValidate = theta0 + theta1*xTest

# result = (yTest - yValidate)**2

print(f'the number of iterations are {count}')
print(f"The error is {err}")
print(f'theta0 is: {theta0} theta1 is: {theta1}, Y validation for test data is \n{yValidate}')


with open("result_1.txt", "a") as f:
  print(f'the number of iterations are {count}', file=f)
  print(f"The error is {err}", file=f)
  print(f'theta0 is: {theta0} theta1 is: {theta1}, Y validation for test data is \n{yValidate}', file=f)

